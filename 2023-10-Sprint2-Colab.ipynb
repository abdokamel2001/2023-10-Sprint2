{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ob3VD0OV7ETa5r77F-an74x8GVF0m1i2",
      "authorship_tag": "ABX9TyNyuiq09rdlZttQDic+qpV2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdokamel2001/ASL-Translation-Project/blob/main/2023-10-Sprint2-Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Microsoft Dataset Sign Language Model"
      ],
      "metadata": {
        "id": "61P_xOHYKo71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/MyDrive/AI Team/Tasks/2023-10-Sprint2/MS-ASL\" \"/content\" #Import the dataset"
      ],
      "metadata": {
        "id": "umAGvlW1KpRr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q mediapipe pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlfaKepJWAKq",
        "outputId": "914ea974-4e95-4dee-c07d-4ce878ed317b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.6/33.6 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import mediapipe as mp\n",
        "import tensorflow as tf\n",
        "from pytube import YouTube\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.core.display import clear_output"
      ],
      "metadata": {
        "id": "QfcW86rkDHf6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pick 50 Examples"
      ],
      "metadata": {
        "id": "lhPypBlT_Zgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nourhan's Code Here\n",
        "\n"
      ],
      "metadata": {
        "id": "f6usK90M_Z1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MediaPipe Functions"
      ],
      "metadata": {
        "id": "VZidz-SQUZKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hands = mp.solutions.hands.Hands()\n",
        "pose = mp.solutions.pose.Pose()\n",
        "face_mesh = mp.solutions.face_mesh.FaceMesh()"
      ],
      "metadata": {
        "id": "W_T58ZVsURq2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_frame_landmarks(frame):\n",
        "    \"\"\"\n",
        "    Extracts landmarks from a single video frame using MediaPipe.\n",
        "\n",
        "    Args:\n",
        "        frame: A single rgb frame/image.\n",
        "\n",
        "    Returns:\n",
        "        np.array: A NumPy array containing extracted landmarks.\n",
        "        The output dimensions are (n, 3) array, where n is the number of landmarks.\n",
        "        Each row in the array represents a landmark, and each landmark is represented\n",
        "        as [x, y, z], where x, y, and z are the normalized coordinates of the landmark.\n",
        "    \"\"\"\n",
        "\n",
        "    results_hands = hands.process(frame)\n",
        "    results_pose = pose.process(frame)\n",
        "    results_face = face_mesh.process(frame)\n",
        "\n",
        "    num_landmarks_per_hand = 21\n",
        "    num_landmarks_body_pose = 33\n",
        "    num_landmarks_face = 117         # Max 468\n",
        "\n",
        "    left_hand_landmarks = np.zeros((num_landmarks_per_hand, 3))\n",
        "    right_hand_landmarks = np.zeros((num_landmarks_per_hand, 3))\n",
        "    body_pose_landmarks = np.zeros((num_landmarks_body_pose, 3))\n",
        "    face_landmarks = np.zeros((num_landmarks_face, 3))\n",
        "\n",
        "    if results_hands.multi_hand_landmarks:\n",
        "        for i, landmarks in enumerate(results_hands.multi_hand_landmarks):\n",
        "            if i == 0:\n",
        "                left_hand_landmarks = np.array([(lm.x, lm.y, lm.z) for lm in landmarks.landmark])\n",
        "            elif i == 1:\n",
        "                right_hand_landmarks = np.array([(lm.x, lm.y, lm.z) for lm in landmarks.landmark])\n",
        "\n",
        "    if results_pose.pose_landmarks:\n",
        "        body_pose_landmarks = np.array([(lm.x, lm.y, lm.z) for lm in results_pose.pose_landmarks.landmark])\n",
        "\n",
        "    if results_face.multi_face_landmarks:\n",
        "        # face_landmarks = np.array([(lm.x, lm.y, lm.z) for lm in results_face.multi_face_landmarks[0].landmark[::468 // num_landmarks_face]])\n",
        "        face_landmarks = np.array([(lm.x, lm.y, lm.z) for lm in results_face.multi_face_landmarks[0].landmark])\n",
        "\n",
        "    return np.vstack((left_hand_landmarks, right_hand_landmarks, body_pose_landmarks, face_landmarks))"
      ],
      "metadata": {
        "id": "IYas6kbVUUQX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_landmarks(video_path):\n",
        "    \"\"\"\n",
        "    Extracts landmarks from a video by processing each frame in the video.\n",
        "\n",
        "    Args:\n",
        "        video_path (str): The file path to the video to process.\n",
        "\n",
        "    Returns:\n",
        "        np.array: A NumPy array where each row corresponds to the landmarks\n",
        "        extracted from a single frame of the video. The dimensions of the output array\n",
        "        are (m, n, 3), where m is the number of frames and n is the number of landmarks.\n",
        "        Each element in the array is a 3D coordinate representing a landmark's position.\n",
        "    \"\"\"\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    all_frame_landmarks = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret: break\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        frame_landmarks = get_frame_landmarks(frame_rgb)\n",
        "        all_frame_landmarks.append(frame_landmarks)\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    return np.array(all_frame_landmarks)"
      ],
      "metadata": {
        "id": "cPgwih22UWKe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the json data"
      ],
      "metadata": {
        "id": "B4plkFCSY_Wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/MS-ASL/MSASL_train.json\", 'r') as json_file:\n",
        "    train_data = json.load(json_file)  # A list of dictionaries"
      ],
      "metadata": {
        "id": "vGgzKAttY8Q1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define directories"
      ],
      "metadata": {
        "id": "jrH_FlB6ZAyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_dir = '/content/train-videos'\n",
        "npy_dir = '/content/train-numpy'\n",
        "os.makedirs(video_dir, exist_ok=True)\n",
        "os.makedirs(npy_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "XrkmuW2QZIVx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize ID sets"
      ],
      "metadata": {
        "id": "wbkTrZyZZSgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "downloaded_video_ids = set()\n",
        "failed_video_ids = set()\n",
        "\n",
        "for filename in os.listdir(video_dir):\n",
        "    if filename.endswith('.mp4'):\n",
        "        video_id = filename.split('.')[0]\n",
        "        downloaded_video_ids.add(video_id)"
      ],
      "metadata": {
        "id": "tyicFoCyZUOd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Iterate through the data"
      ],
      "metadata": {
        "id": "YQCzLg7vZnm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    for i in tqdm(range(len(train_data)), ncols=100):\n",
        "        url = train_data[i]['url']\n",
        "        video_id = url.split('=')[1]\n",
        "        video_path = os.path.join(video_dir, f'{video_id}.mp4')\n",
        "        npy_path = os.path.join(npy_dir, f'{video_id}.npy')\n",
        "\n",
        "        if video_id not in downloaded_video_ids and video_id not in failed_video_ids:\n",
        "            try:\n",
        "                yt = YouTube(url)\n",
        "                stream = yt.streams.get_highest_resolution()\n",
        "                stream.download(output_path=video_dir, filename=f'{video_id}.mp4')\n",
        "                video_landmarks = get_video_landmarks(video_path)\n",
        "                np.save(npy_path, video_landmarks)\n",
        "                os.remove(video_path)\n",
        "                downloaded_video_ids.add(video_id)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"\\nError downloading {video_id}: {e}\")\n",
        "                if os.path.exists(video_path):\n",
        "                    os.remove(video_path)\n",
        "                failed_video_ids.add(video_id)\n",
        "                continue\n",
        "\n",
        "        clear_output(True)\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    for f in os.listdir(video_dir):\n",
        "        file_path = os.path.join(video_dir, f)\n",
        "        if os.path.isfile(file_path):\n",
        "            os.remove(file_path)\n",
        "    print(\"\\nLoading process interrupted by user.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GC9AV4Tful7",
        "outputId": "cbe567aa-6662-4240-f93d-c1954732aa4a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|                                                         | 20/16054 [01:53<25:16:34,  5.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading process interrupted by user.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Downloaded Videos ({len(downloaded_video_ids)}): {downloaded_video_ids}')\n",
        "print(f'Failed Videos ({len(failed_video_ids)}): {failed_video_ids}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQNvth68m6Ai",
        "outputId": "1d725322-9f23-4f7b-b30b-5b6b0bb8ac7c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded Videos (0): set()\n",
            "Failed Videos (0): set()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "WdcgF0Bu1nQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Useful Shortcuts"
      ],
      "metadata": {
        "id": "qBAOQjuWfOfg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zip to Download"
      ],
      "metadata": {
        "id": "nIJDuF6-1gBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -q -r /content/train-numpy.zip -j /content/train-numpy"
      ],
      "metadata": {
        "id": "qrzcDYZ31MgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unzip to Reload"
      ],
      "metadata": {
        "id": "2plZs1hb1ig0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/train-numpy.zip -d /content/train-numpy/"
      ],
      "metadata": {
        "id": "Kcf_mA3t1cPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "a7UGfIQpc4GV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Export to Drive"
      ],
      "metadata": {
        "id": "lE5c3cuUerA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/train-numpy\" \"/content/drive/MyDrive/AI Team/Varying/MS-Train-Numpy\""
      ],
      "metadata": {
        "id": "XkmhEum_c4zY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import from Drive"
      ],
      "metadata": {
        "id": "ViX6eBpJfEvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/MyDrive/AI Team/Varying/MS-Train-Numpy\" \"/content/train-numpy\""
      ],
      "metadata": {
        "id": "K9WrBvo3eqnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "xLgC6yKbfHWX"
      }
    }
  ]
}